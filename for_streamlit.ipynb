{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8df9435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-tests 0.3.20 requires langchain-core<1.0.0,>=0.3.63, but you have langchain-core 0.2.43 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-pinecone==0.1.1 langchain_community langchain langchainhub python-dotenv langchain_core langchain_openai pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74337db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ---------------\n",
      "aiohappyeyeballs          2.6.1\n",
      "aiohttp                   3.12.14\n",
      "aiohttp-retry             2.9.1\n",
      "aiosignal                 1.4.0\n",
      "annotated-types           0.7.0\n",
      "anyio                     4.9.0\n",
      "appnope                   0.1.4\n",
      "asttokens                 3.0.0\n",
      "attrs                     25.3.0\n",
      "certifi                   2025.7.14\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.2\n",
      "comm                      0.2.2\n",
      "dataclasses-json          0.6.7\n",
      "debugpy                   1.8.15\n",
      "decorator                 5.2.1\n",
      "distro                    1.9.0\n",
      "executing                 2.2.0\n",
      "frozenlist                1.7.0\n",
      "h11                       0.16.0\n",
      "httpcore                  1.0.9\n",
      "httpx                     0.28.1\n",
      "httpx-sse                 0.4.1\n",
      "idna                      3.10\n",
      "iniconfig                 2.1.0\n",
      "ipykernel                 6.29.5\n",
      "ipython                   9.4.0\n",
      "ipython_pygments_lexers   1.1.1\n",
      "jedi                      0.19.2\n",
      "jiter                     0.10.0\n",
      "jsonpatch                 1.33\n",
      "jsonpointer               3.0.0\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.8.1\n",
      "langchain                 0.2.17\n",
      "langchain-community       0.2.19\n",
      "langchain-core            0.2.43\n",
      "langchain-openai          0.1.25\n",
      "langchain-pinecone        0.1.1\n",
      "langchain-tests           0.3.20\n",
      "langchain-text-splitters  0.2.4\n",
      "langchainhub              0.1.21\n",
      "langsmith                 0.1.147\n",
      "markdown-it-py            3.0.0\n",
      "marshmallow               3.26.1\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "multidict                 6.6.3\n",
      "mypy_extensions           1.1.0\n",
      "nest-asyncio              1.6.0\n",
      "numpy                     1.26.4\n",
      "openai                    1.97.0\n",
      "orjson                    3.11.0\n",
      "packaging                 24.2\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pinecone                  7.3.0\n",
      "pinecone-client           3.2.2\n",
      "pinecone-plugin-assistant 1.7.0\n",
      "pinecone-plugin-interface 0.0.7\n",
      "pip                       24.0\n",
      "platformdirs              4.3.8\n",
      "pluggy                    1.6.0\n",
      "prompt_toolkit            3.0.51\n",
      "propcache                 0.3.2\n",
      "psutil                    7.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "py-cpuinfo                9.0.0\n",
      "pycparser                 2.22\n",
      "pydantic                  2.11.7\n",
      "pydantic_core             2.33.2\n",
      "pydantic-settings         2.10.1\n",
      "Pygments                  2.19.2\n",
      "pytest                    8.4.1\n",
      "pytest-asyncio            0.26.0\n",
      "pytest-benchmark          5.1.0\n",
      "pytest-codspeed           4.0.0\n",
      "pytest-recording          0.13.4\n",
      "pytest-socket             0.7.0\n",
      "python-dateutil           2.9.0.post0\n",
      "python-dotenv             1.1.1\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     27.0.0\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.4\n",
      "requests-toolbelt         1.0.0\n",
      "rich                      14.0.0\n",
      "setuptools                65.5.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "SQLAlchemy                2.0.41\n",
      "stack-data                0.6.3\n",
      "syrupy                    4.9.1\n",
      "tenacity                  8.5.0\n",
      "tiktoken                  0.9.0\n",
      "tornado                   6.5.1\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "types-requests            2.32.4.20250611\n",
      "typing_extensions         4.14.1\n",
      "typing-inspect            0.9.0\n",
      "typing-inspection         0.4.1\n",
      "urllib3                   2.5.0\n",
      "vcrpy                     7.0.0\n",
      "wcwidth                   0.2.13\n",
      "wrapt                     1.17.2\n",
      "yarl                      1.20.1\n",
      "zstandard                 0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c521523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (7.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone) (2025.7.14)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone) (1.7.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone) (4.14.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/julianajang/.pyenv/versions/inflearn-streamlit/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone streamlit --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba639a02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstreamlit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mst\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPrompxtTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"ì†Œë“ì„¸ ì±—ë´‡\", page_icon=\"ğŸ¤–\")\n",
    "st.title(\"ğŸ¤– ì†Œë“ì„¸ ì±—ë´‡\")\n",
    "st.caption(\"ì†Œë“ì„¸ì— ê´€ë ¨ëœ ë‹µë³€ì„ ëª¨ë‘ ë‹µí•´ë“œë¦½ë‹ˆë‹¤! \")\n",
    "\n",
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "## pinecone í™œìš©\n",
    "# Initialize a Pinecone client with your API key\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "def get_ai_message(user_message):\n",
    "    # ì„ë² ë”© ìƒì„±í•˜ê¸°\n",
    "    embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    # ë°ì´í„°ë¥¼ ì²˜ìŒ ì €ì¥í•  ë•Œ\n",
    "    index_name = 'tax-markdown-index'\n",
    "    # llmì— ì§ˆì˜ í•˜ê¸°\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    # Initialize the PineconeVectorStore\n",
    "    database = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        embedding=embedding\n",
    "    )\n",
    "\n",
    "    \n",
    "    ## í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    retriever=database.as_retriever(search_kwargs={'k':4})\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt}  # í”„ë¡¬í”„íŠ¸ë¥¼ ì§€ì •\n",
    "    )\n",
    "\n",
    "    query = \"ì—°ë´‰ 5000ë§Œì›ì˜ ì§ì¥ì¸ì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì¸ê°€ìš”? \"\n",
    "\n",
    "    dictionary = \"\\n\".join([\n",
    "        \"ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì\"\n",
    "    ])\n",
    "    prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”\n",
    "                ë§Œì•½ì— ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ì´ ë˜ë©´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤\n",
    "                ì‚¬ì „ : {dictionary}\n",
    "                ì§ˆë¬¸ : {{question}}\n",
    "                \"\"\")\n",
    "\n",
    "    dictionary_chain = prompt | llm | StrOutputParser()\n",
    "    tax_chain = {\"query\": dictionary_chain} | qa_chain\n",
    "    ai_message = tax_chain.invoke({\"question\": user_message})\n",
    "\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'message_list' not in st.session_state:\n",
    "    st.session_state.message_list = []\n",
    "for message in st.session_state.message_list : \n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "if user_question := st.chat_input(placeholder=\"ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ ì£¼ì„¸ìš”\"):\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_question)\n",
    "    st.session_state.message_list.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "    ai_message = get_ai_message(user_question)\n",
    "\n",
    "    with st.chat_message(\"ai\"):\n",
    "        st.write(ai_message)\n",
    "    st.session_state.message_list.append({\"role\": \"ai\", \"content\": ai_message})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding ìƒì„±\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import time\n",
    "\n",
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±í•˜ê¸°\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "## pinecone í™œìš©\n",
    "# Initialize a Pinecone client with your API key\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ì²˜ìŒ ì €ì¥í•  ë•Œ\n",
    "index_name = 'tax-index'\n",
    "# llmì— ì§ˆì˜ í•˜ê¸°\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "# Initialize the PineconeVectorStore\n",
    "database = PineconeVectorStore.from_documents(\n",
    "    documents=[],  # Start with an empty list\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "\n",
    "query = \"ì—°ë´‰ 5000ë§Œì›ì˜ ì§ì¥ì¸ì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì¸ê°€ìš”? \"\n",
    "\n",
    "## í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "retriever=database.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}  # í”„ë¡¬í”„íŠ¸ë¥¼ ì§€ì •\n",
    ")\n",
    "\n",
    "\n",
    "dictionary = \"\\n\".join([\n",
    "    \"ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì\",\n",
    "    \"ê·¼ë¡œì -> ì§ì¥ì¸\",\n",
    "])\n",
    "prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”\n",
    "            ë§Œì•½ì— ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ì´ ë˜ë©´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤\n",
    "            ì‚¬ì „ : {dictionary}\n",
    "            ì§ˆë¬¸ : {{question}}\n",
    "            \"\"\")\n",
    "\n",
    "dictionary_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "new_question = dictionary_chain.invoke({\n",
    "    \"question\": query,\n",
    "    \"dictionary\": dictionary  # ì—¬ê¸°ë¥¼ ê¼­ ë„£ì–´ì¤˜ì•¼ í•¨!\n",
    "})\n",
    "tax_chain = {\"query\": dictionary_chain} | qa_chain\n",
    "ai_response = tax_chain.invoke({\"question\":query})\n",
    "ai_response \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
